{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-01T22:40:43.118068Z","iopub.execute_input":"2023-11-01T22:40:43.118466Z","iopub.status.idle":"2023-11-01T22:40:43.131267Z","shell.execute_reply.started":"2023-11-01T22:40:43.118410Z","shell.execute_reply":"2023-11-01T22:40:43.130452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SUMMARY OF STATEMENT**","metadata":{}},{"cell_type":"markdown","source":"The JPX Tokyo Stock Exchange Prediction Hackathon is a competitive event where data scientists and financial experts come together to create predictive models for stock performance on the Tokyo Stock Exchange (TSE). Participants use historical stock data and other relevant information to develop algorithms and machine learning models that can forecast stock price movements. This hackathon fosters innovation, collaboration, and the development of valuable tools for investors and traders in the Japanese stock market. It offers participants the chance to win prizes and gain recognition for their predictive models and strategies.\n","metadata":{}},{"cell_type":"markdown","source":"**Exploratory Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis (EDA) of the JPX Tokyo Stock Exchange prediction involves the systematic examination and visualization of historical stock market data related to the Tokyo Stock Exchange (JPX). EDA techniques are employed to gain insights into patterns, trends, and potential predictors that can inform the development of predictive models for stock price movements. By examining variables like trading volume, price trends, volatility, and macroeconomic indicators, EDA aims to identify key factors influencing stock market behavior in the JPX and lay the groundwork for more advanced predictive modeling and trading strategies. This process helps analysts and investors better understand the dynamics of the Tokyo Stock Exchange and make informed decisions based on data-driven insights.","metadata":{}},{"cell_type":"code","source":"import warnings, gc\nimport numpy as np \nimport pandas as pd\nimport matplotlib.colors\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom lightgbm import LGBMRegressor\nfrom decimal import ROUND_HALF_UP, Decimal\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\nimport tqdm\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.tri as tri\nimport seaborn as sns\nfrom scipy.optimize import minimize, Bounds, LinearConstraint, linprog\n\ninit_notebook_mode(connected=True)\ntemp = dict(layout=go.Layout(font=dict(family=\"Franklin Gothic\", size=12), width=800))\ncolors=px.colors.qualitative.Plotly\n\ntrain=pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\", parse_dates=['Date'])\nstock_list=pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\n\nprint(\"The training data begins on {} and ends on {}.\\n\".format(train.Date.min(),train.Date.max()))\ndisplay(train.describe().style.format('{:,.2f}'))","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:43.133393Z","iopub.execute_input":"2023-11-01T22:40:43.133932Z","iopub.status.idle":"2023-11-01T22:40:49.083021Z","shell.execute_reply.started":"2023-11-01T22:40:43.133903Z","shell.execute_reply":"2023-11-01T22:40:49.081936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_date=train.Date.unique()\nreturns=train.groupby('Date')['Target'].mean().mul(100).rename('Average Return')\nclose_avg=train.groupby('Date')['Close'].mean().rename('Closing Price')\nvol_avg=train.groupby('Date')['Volume'].mean().rename('Volume')\n\nfig = make_subplots(rows=3, cols=1, \n                    shared_xaxes=True)\nfor i, j in enumerate([returns, close_avg, vol_avg]):\n    fig.add_trace(go.Scatter(x=train_date, y=j, mode='lines',\n                             name=j.name, marker_color=colors[i]), row=i+1, col=1)\nfig.update_xaxes(rangeslider_visible=False,\n                 rangeselector=dict(\n                     buttons=list([\n                         dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n                         dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n                         dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n                         dict(step=\"all\")])),\n                 row=1,col=1)\nfig.update_layout(template=temp,title='JPX Market Average Stock Return, Closing Price, and Shares Traded', \n                  hovermode='x unified', height=700, \n                  yaxis1=dict(title='Stock Return', ticksuffix='%'), \n                  yaxis2_title='Closing Price', yaxis3_title='Shares Traded',\n                  showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:49.084494Z","iopub.execute_input":"2023-11-01T22:40:49.084831Z","iopub.status.idle":"2023-11-01T22:40:49.728047Z","shell.execute_reply.started":"2023-11-01T22:40:49.084804Z","shell.execute_reply":"2023-11-01T22:40:49.726941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"stock_list['SectorName']=[i.rstrip().lower().capitalize() for i in stock_list['17SectorName']]\nstock_list['Name']=[i.rstrip().lower().capitalize() for i in stock_list['Name']]\ntrain_df = train.merge(stock_list[['SecuritiesCode','Name','SectorName']], on='SecuritiesCode', how='left')\ntrain_df['Year'] = train_df['Date'].dt.year\nyears = {year: pd.DataFrame() for year in train_df.Year.unique()[::-1]}\nfor key in years.keys():\n    df=train_df[train_df.Year == key]\n    years[key] = df.groupby('SectorName')['Target'].mean().mul(100).rename(\"Avg_return_{}\".format(key))\ndf=pd.concat((years[i].to_frame() for i in years.keys()), axis=1)\ndf=df.sort_values(by=\"Avg_return_2021\")\n\nfig = make_subplots(rows=1, cols=5, shared_yaxes=True)\nfor i, col in enumerate(df.columns):\n    x = df[col]\n    mask = x<=0\n    fig.add_trace(go.Bar(x=x[mask], y=df.index[mask],orientation='h', \n                         text=x[mask], texttemplate='%{text:.2f}%',textposition='auto',\n                         hovertemplate='Average Return in %{y} Stocks = %{x:.4f}%',\n                         marker=dict(color='red', opacity=0.7),name=col[-4:]), \n                  row=1, col=i+1)\n    fig.add_trace(go.Bar(x=x[~mask], y=df.index[~mask],orientation='h', \n                         text=x[~mask], texttemplate='%{text:.2f}%', textposition='auto', \n                         hovertemplate='Average Return in %{y} Stocks = %{x:.4f}%',\n                         marker=dict(color='green', opacity=0.7),name=col[-4:]), \n                  row=1, col=i+1)\n    fig.update_xaxes(range=(x.min()-.15,x.max()+.15), title='{} Returns'.format(col[-4:]), \n                     showticklabels=False, row=1, col=i+1)\nfig.update_layout(template=temp,title='Yearly Average Stock Returns by Sector', \n                  hovermode='closest',margin=dict(l=250,r=50),\n                  height=600, width=1000, showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:49.729684Z","iopub.execute_input":"2023-11-01T22:40:49.729982Z","iopub.status.idle":"2023-11-01T22:40:50.938925Z","shell.execute_reply.started":"2023-11-01T22:40:49.729958Z","shell.execute_reply":"2023-11-01T22:40:50.937906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_df=train_df[train_df.Date>'2020-12-23']\nprint(\"New Train Shape {}.\\nMissing values in Target = {}\".format(train_df.shape,train_df['Target'].isna().sum()))","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:50.941796Z","iopub.execute_input":"2023-11-01T22:40:50.942095Z","iopub.status.idle":"2023-11-01T22:40:51.028099Z","shell.execute_reply.started":"2023-11-01T22:40:50.942069Z","shell.execute_reply":"2023-11-01T22:40:51.026943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nx_hist=train_df['Target']\nfig.add_trace(go.Histogram(x=x_hist*100,\n                           marker=dict(color=colors[0], opacity=0.7, \n                                       line=dict(width=1, color=colors[0])),\n                           xbins=dict(start=-40,end=40,size=1)))\nfig.update_layout(template=temp,title='Target Distribution', \n                  xaxis=dict(title='Stock Return',ticksuffix='%'), height=450)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:51.029111Z","iopub.execute_input":"2023-11-01T22:40:51.029393Z","iopub.status.idle":"2023-11-01T22:40:51.774941Z","shell.execute_reply.started":"2023-11-01T22:40:51.029369Z","shell.execute_reply":"2023-11-01T22:40:51.773834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pal = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, 18)]\nfig = go.Figure()\nfor i, sector in enumerate(df.index[::-1]):\n    y_data=train_df[train_df['SectorName']==sector]['Target']\n    fig.add_trace(go.Box(y=y_data*100, name=sector,\n                         marker_color=pal[i], showlegend=False))\nfig.update_layout(template=temp, title='Target Distribution by Sector',\n                  yaxis=dict(title='Stock Return',ticksuffix='%'),\n                  margin=dict(b=150), height=750, width=900)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:51.776198Z","iopub.execute_input":"2023-11-01T22:40:51.776550Z","iopub.status.idle":"2023-11-01T22:40:53.905596Z","shell.execute_reply.started":"2023-11-01T22:40:51.776519Z","shell.execute_reply":"2023-11-01T22:40:53.904170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_date=train_df.Date.unique()\nsectors=train_df.SectorName.unique().tolist()\nsectors.insert(0, 'All')\nopen_avg=train_df.groupby('Date')['Open'].mean()\nhigh_avg=train_df.groupby('Date')['High'].mean()\nlow_avg=train_df.groupby('Date')['Low'].mean()\nclose_avg=train_df.groupby('Date')['Close'].mean() \nbuttons=[]\n\nfig = go.Figure()\nfor i in range(18):\n    if i != 0:\n        open_avg=train_df[train_df.SectorName==sectors[i]].groupby('Date')['Open'].mean()\n        high_avg=train_df[train_df.SectorName==sectors[i]].groupby('Date')['High'].mean()\n        low_avg=train_df[train_df.SectorName==sectors[i]].groupby('Date')['Low'].mean()\n        close_avg=train_df[train_df.SectorName==sectors[i]].groupby('Date')['Close'].mean()        \n    \n    fig.add_trace(go.Candlestick(x=train_date, open=open_avg, high=high_avg,\n                                 low=low_avg, close=close_avg, name=sectors[i],\n                                 visible=(True if i==0 else False)))\n    \n    visibility=[False]*len(sectors)\n    visibility[i]=True\n    button = dict(label = sectors[i],\n                  method = \"update\",\n                  args=[{\"visible\": visibility}])\n    buttons.append(button)\n    \nfig.update_xaxes(rangeslider_visible=True,\n                 rangeselector=dict(\n                     buttons=list([\n                         dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n                         dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n                         dict(step=\"all\")]), xanchor='left',yanchor='bottom', y=1.16, x=.01))\nfig.update_layout(template=temp,title='Stock Price Movements by Sector', \n                  hovermode='x unified', showlegend=False, width=1000,\n                  updatemenus=[dict(active=0, type=\"dropdown\",\n                                    buttons=buttons, xanchor='left',\n                                    yanchor='bottom', y=1.01, x=.01)],\n                  yaxis=dict(title='Stock Price'))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:53.907204Z","iopub.execute_input":"2023-11-01T22:40:53.907770Z","iopub.status.idle":"2023-11-01T22:40:59.456463Z","shell.execute_reply.started":"2023-11-01T22:40:53.907720Z","shell.execute_reply":"2023-11-01T22:40:59.455578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks=train_df[train_df.SecuritiesCode.isin([4169,7089,4582,2158,7036])]\ndf_pivot=stocks.pivot_table(index='Date', columns='Name', values='Close').reset_index()\npal=['rgb'+str(i) for i in sns.color_palette(\"coolwarm\", len(df_pivot))]\n\nfig = ff.create_scatterplotmatrix(df_pivot.iloc[:,1:], diag='histogram', name='')\nfig.update_traces(marker=dict(color=pal, opacity=0.9, line_color='white', line_width=.5))\nfig.update_layout(template=temp, title='Scatterplots of Highest Performing Stocks', \n                  height=1000, width=1000, showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:40:59.457701Z","iopub.execute_input":"2023-11-01T22:40:59.458668Z","iopub.status.idle":"2023-11-01T22:41:00.051753Z","shell.execute_reply.started":"2023-11-01T22:40:59.458629Z","shell.execute_reply":"2023-11-01T22:41:00.050657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr=train_df.groupby('SecuritiesCode')[['Target','Close']].corr().unstack().iloc[:,1]\nstocks=corr.nlargest(10).rename(\"Return\").reset_index()\nstocks=stocks.merge(train_df[['Name','SecuritiesCode']], on='SecuritiesCode').drop_duplicates()\npal=sns.color_palette(\"magma_r\", 14).as_hex()\nrgb=['rgba'+str(matplotlib.colors.to_rgba(i,0.7)) for i in pal]\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=stocks.Name, y=stocks.Return, text=stocks.Return, \n                     texttemplate='%{text:.2f}', name='', width=0.8,\n                     textposition='outside',marker=dict(color=rgb, line=dict(color=pal,width=1)),\n                     hovertemplate='Correlation of %{x} with target = %{y:.3f}'))\nfig.update_layout(template=temp, title='Most Correlated Stocks with Target Variable',\n                  yaxis=dict(title='Correlation',showticklabels=False), \n                  xaxis=dict(title='Stock',tickangle=45), margin=dict(b=100),\n                  width=800,height=500)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:00.053113Z","iopub.execute_input":"2023-11-01T22:41:00.053466Z","iopub.status.idle":"2023-11-01T22:41:00.478703Z","shell.execute_reply.started":"2023-11-01T22:41:00.053436Z","shell.execute_reply":"2023-11-01T22:41:00.477733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pivot=train_df.pivot_table(index='Date', columns='SectorName', values='Close').reset_index()\ncorr=df_pivot.corr().round(2)\nmask=np.triu(np.ones_like(corr, dtype=bool))\nc_mask = np.where(~mask, corr, 100)\nc=[]\nfor i in c_mask.tolist()[1:]:\n    c.append([x for x in i if x != 100])\n    \ncor=c[::-1]\nx=corr.index.tolist()[:-1]\ny=corr.columns.tolist()[1:][::-1]\nfig=ff.create_annotated_heatmap(z=cor, x=x, y=y, \n                                hovertemplate='Correlation between %{x} and %{y} stocks = %{z}',\n                                colorscale='viridis', name='')\nfig.update_layout(template=temp, title='Stock Correlation between Sectors',\n                  margin=dict(l=250,t=270),height=800,width=900,\n                  yaxis=dict(showgrid=False, autorange='reversed'),\n                  xaxis=dict(showgrid=False))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:00.480014Z","iopub.execute_input":"2023-11-01T22:41:00.480887Z","iopub.status.idle":"2023-11-01T22:41:00.832747Z","shell.execute_reply.started":"2023-11-01T22:41:00.480857Z","shell.execute_reply":"2023-11-01T22:41:00.831684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Engineering**","metadata":{}},{"cell_type":"markdown","source":"Feature engineering for JPX Tokyo Stock Exchange prediction involves the careful selection and transformation of relevant data attributes to enhance the performance of predictive models. This process aims to create informative, meaningful features from raw market data, such as stock prices, trading volumes, and economic indicators. Techniques may include creating lag variables, rolling averages, and technical indicators like moving averages or relative strength indexes. Feature engineering is crucial for capturing hidden patterns and relationships in the data, improving the predictive accuracy of models, and ultimately assisting in making more accurate forecasts of stock price movements in the JPX. It plays a pivotal role in developing sophisticated trading strategies and risk management in the realm of stock market prediction.","metadata":{}},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n    \n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n    return price\n\ntrain=train.drop('ExpectedDividend',axis=1).fillna(0)\nprices=adjust_price(train)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:00.833973Z","iopub.execute_input":"2023-11-01T22:41:00.834252Z","iopub.status.idle":"2023-11-01T22:41:18.939948Z","shell.execute_reply.started":"2023-11-01T22:41:00.834227Z","shell.execute_reply":"2023-11-01T22:41:18.938930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features(df):\n    df=df.copy()\n    col='AdjustedClose'\n    periods=[5,10,20,30,50]\n    for period in periods:\n        df.loc[:,\"Return_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].pct_change(period)\n        df.loc[:,\"MovingAvg_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].rolling(window=period).mean().values\n        df.loc[:,\"ExpMovingAvg_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].ewm(span=period,adjust=False).mean().values\n        df.loc[:,\"Volatility_{}Day\".format(period)] = np.log(df[col]).groupby(df[\"SecuritiesCode\"]).diff().rolling(period).std()\n    return df\n\nprice_features=create_features(df=prices)\nprice_features.drop(['RowId','SupervisionFlag','AdjustmentFactor','CumulativeAdjustmentFactor','Close'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:18.941208Z","iopub.execute_input":"2023-11-01T22:41:18.941572Z","iopub.status.idle":"2023-11-01T22:41:29.452652Z","shell.execute_reply.started":"2023-11-01T22:41:18.941544Z","shell.execute_reply":"2023-11-01T22:41:29.451459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_names=price_features.merge(stock_list[['SecuritiesCode','Name','SectorName']], on='SecuritiesCode').set_index('Date')\nprice_names=price_names[price_names.index>='2020-12-29']\nprice_names.fillna(0, inplace=True)\n\nfeatures=['MovingAvg','ExpMovingAvg','Return', 'Volatility']\nnames=['Average', 'Exp. Moving Average', 'Period', 'Volatility']\nbuttons=[]\n\nfig = make_subplots(rows=2, cols=2, \n                    shared_xaxes=True, \n                    vertical_spacing=0.1,\n                    subplot_titles=('Adjusted Close Moving Average',\n                                    'Exponential Moving Average',\n                                    'Stock Return', 'Stock Volatility'))\n\nfor i, sector in enumerate(price_names.SectorName.unique()):\n    \n    sector_df=price_names[price_names.SectorName==sector]\n    periods=[0,10,30,50]\n    colors=px.colors.qualitative.Vivid\n    dash=['solid','dash', 'longdash', 'dashdot', 'longdashdot']\n    row,col=1,1\n    \n    for j, (feature, name) in enumerate(zip(features, names)):\n        if j>=2:\n            row,periods=2,[10,30,50]\n            colors=px.colors.qualitative.Bold[1:]\n        if j%2==0:\n            col=1\n        else:\n            col=2\n        \n        for k, period in enumerate(periods):\n            if (k==0)&(j<2):\n                plot_data=sector_df.groupby(sector_df.index)['AdjustedClose'].mean().rename('Adjusted Close')\n            elif j>=2:\n                plot_data=sector_df.groupby(sector_df.index)['{}_{}Day'.format(feature,period)].mean().mul(100).rename('{}-day {}'.format(period,name))\n            else:\n                plot_data=sector_df.groupby(sector_df.index)['{}_{}Day'.format(feature,period)].mean().rename('{}-day {}'.format(period,name))\n            fig.add_trace(go.Scatter(x=plot_data.index, y=plot_data, mode='lines',\n                                     name=plot_data.name, marker_color=colors[k+1],\n                                     line=dict(width=2,dash=(dash[k] if j<2 else 'solid')), \n                                     showlegend=(True if (j==0) or (j==2) else False), legendgroup=row,\n                                     visible=(False if i != 0 else True)), row=row, col=col)\n            \n    visibility=[False]*14*len(price_names.SectorName.unique())\n    for l in range(i*14, i*14+14):\n        visibility[l]=True\n    button = dict(label = sector,\n                  method = \"update\",\n                  args=[{\"visible\": visibility}])\n    buttons.append(button)\n\nfig.update_layout(title='Stock Price Moving Average, Return,<br>and Volatility by Sector',\n                  template=temp, yaxis3_ticksuffix='%', yaxis4_ticksuffix='%',\n                  legend_title_text='Period', legend_tracegroupgap=250,\n                  updatemenus=[dict(active=0, type=\"dropdown\",\n                                    buttons=buttons, xanchor='left',\n                                    yanchor='bottom', y=1.105, x=.01)], \n                  hovermode='x unified', height=800,width=1200, margin=dict(t=150))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:29.457224Z","iopub.execute_input":"2023-11-01T22:41:29.457564Z","iopub.status.idle":"2023-11-01T22:41:35.750057Z","shell.execute_reply.started":"2023-11-01T22:41:29.457537Z","shell.execute_reply":"2023-11-01T22:41:35.748813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**STOCK PRICE PREDICTION**","metadata":{}},{"cell_type":"markdown","source":"Stock prediction for the JPX Tokyo Stock Exchange is a complex and data-driven process that involves using various techniques and models to forecast the future price movements of stocks traded on the exchange. The goal of stock prediction is to assist investors, traders, and financial analysts in making informed decisions and managing their portfolios more effectively.\n\nSeveral methods can be employed for stock prediction on the JPX Tokyo Stock Exchange, including time series analysis, machine learning algorithms, and deep learning models. These approaches leverage historical stock price data, trading volumes, economic indicators, news sentiment analysis, and other relevant information to make predictions. Feature engineering and exploratory data analysis are crucial steps to extract valuable insights from the data.\n\nThe accuracy of stock prediction models varies, and it is important to understand that stock markets are influenced by a multitude of factors, making precise predictions challenging. Nevertheless, these models can provide valuable insights, helping stakeholders identify trends, risks, and opportunities in the market.\n\nInvestors and financial professionals often use stock predictions to inform their trading strategies, risk management decisions, and asset allocation. It is important to keep in mind that stock predictions are inherently uncertain and should be used in conjunction with thorough research and financial analysis to make well-informed investment choices.","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:35.751401Z","iopub.execute_input":"2023-11-01T22:41:35.751799Z","iopub.status.idle":"2023-11-01T22:41:35.762182Z","shell.execute_reply.started":"2023-11-01T22:41:35.751769Z","shell.execute_reply":"2023-11-01T22:41:35.760973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_fold = TimeSeriesSplit(n_splits=10, gap=10000)\nprices=price_features.dropna().sort_values(['Date','SecuritiesCode'])\ny=prices['Target'].to_numpy()\nX=prices.drop(['Target'],axis=1)\n\nfeat_importance=pd.DataFrame()\nsharpe_ratio=[]\n    \nfor fold, (train_idx, val_idx) in enumerate(ts_fold.split(X, y)):\n    \n    print(\"\\n========================== Fold {} ==========================\".format(fold+1))\n    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n    X_valid, y_val = X.iloc[val_idx,:], y[val_idx]\n    \n    print(\"Train Date range: {} to {}\".format(X_train.Date.min(),X_train.Date.max()))\n    print(\"Valid Date range: {} to {}\".format(X_valid.Date.min(),X_valid.Date.max()))\n    \n    X_train.drop(['Date','SecuritiesCode'], axis=1, inplace=True)\n    X_val=X_valid[X_valid.columns[~X_valid.columns.isin(['Date','SecuritiesCode'])]]\n    val_dates=X_valid.Date.unique()[1:-1]\n    print(\"\\nTrain Shape: {} {}, Valid Shape: {} {}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape))\n    \n    params = {'n_estimators': 500,\n              'num_leaves' : 100,\n              'learning_rate': 0.1,\n              'colsample_bytree': 0.9,\n              'subsample': 0.8,\n              'reg_alpha': 0.4,\n              'metric': 'mae',\n              'random_state': 21}\n    \n    gbm = LGBMRegressor(**params).fit(X_train, y_train, \n                                      eval_set=[(X_train, y_train), (X_val, y_val)],\n                                      verbose=300, \n                                      eval_metric=['mae','mse'])\n    y_pred = gbm.predict(X_val)\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    mae = mean_absolute_error(y_val, y_pred)\n    feat_importance[\"Importance_Fold\"+str(fold)]=gbm.feature_importances_\n    feat_importance.set_index(X_train.columns, inplace=True)\n    \n    rank=[]\n    X_val_df=X_valid[X_valid.Date.isin(val_dates)]\n    for i in X_val_df.Date.unique():\n        temp_df = X_val_df[X_val_df.Date == i].drop(['Date','SecuritiesCode'],axis=1)\n        temp_df[\"pred\"] = gbm.predict(temp_df)\n        temp_df[\"Rank\"] = (temp_df[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n        rank.append(temp_df[\"Rank\"].values)\n\n    stock_rank=pd.Series([x for y in rank for x in y], name=\"Rank\")\n    df=pd.concat([X_val_df.reset_index(drop=True),stock_rank,\n                  prices[prices.Date.isin(val_dates)]['Target'].reset_index(drop=True)], axis=1)\n    sharpe=calc_spread_return_sharpe(df)\n    sharpe_ratio.append(sharpe)\n    print(\"Valid Sharpe: {}, RMSE: {}, MAE: {}\".format(sharpe,rmse,mae))\n    \n    del X_train, y_train,  X_val, y_val\n    gc.collect()\n    \nprint(\"\\nAverage cross-validation Sharpe Ratio: {:.4f}, standard deviation = {:.2f}.\".format(np.mean(sharpe_ratio),np.std(sharpe_ratio)))","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:41:35.763881Z","iopub.execute_input":"2023-11-01T22:41:35.764237Z","iopub.status.idle":"2023-11-01T22:50:29.956924Z","shell.execute_reply.started":"2023-11-01T22:41:35.764208Z","shell.execute_reply":"2023-11-01T22:50:29.955837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfeat_importance['avg'] = feat_importance.mean(axis=1)\nfeat_importance = feat_importance.sort_values(by='avg',ascending=True)\npal=sns.color_palette(\"plasma_r\", 29).as_hex()[2:]\n\nfig=go.Figure()\nfor i in range(len(feat_importance.index)):\n    fig.add_shape(dict(type=\"line\", y0=i, y1=i, x0=0, x1=feat_importance['avg'][i], \n                       line_color=pal[::-1][i],opacity=0.7,line_width=4))\nfig.add_trace(go.Scatter(x=feat_importance['avg'], y=feat_importance.index, mode='markers', \n                         marker_color=pal[::-1], marker_size=8,\n                         hovertemplate='%{y} Importance = %{x:.0f}<extra></extra>'))\nfig.update_layout(template=temp,title='Overall Feature Importance', \n                  xaxis=dict(title='Average Importance',zeroline=False),\n                  yaxis_showgrid=False, margin=dict(l=120,t=80),\n                  height=700, width=800)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T22:50:29.958035Z","iopub.execute_input":"2023-11-01T22:50:29.958369Z","iopub.status.idle":"2023-11-01T22:50:30.176410Z","shell.execute_reply.started":"2023-11-01T22:50:29.958341Z","shell.execute_reply":"2023-11-01T22:50:30.175518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_fin=feat_importance.avg.nlargest(3).index.tolist()\ncols_fin.extend(('Open','High','Low'))\nX_train=prices[cols_fin]\ny_train=prices['Target']\ngbm = LGBMRegressor(**params).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T23:42:33.484297Z","iopub.execute_input":"2023-11-01T23:42:33.484784Z","iopub.status.idle":"2023-11-01T23:43:07.384294Z","shell.execute_reply.started":"2023-11-01T23:42:33.484751Z","shell.execute_reply":"2023-11-01T23:43:07.383407Z"},"trusted":true},"execution_count":null,"outputs":[]}]}